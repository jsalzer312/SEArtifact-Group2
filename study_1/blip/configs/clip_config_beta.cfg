models_dir: "/home/yang/BLIP/clip_models"
train_sample_size: 50000
train_batch_size: 512
validation_batch_size: 64
learning_rate: 5.e-5
num_epochs: 10
checkpoint_interval: 1
image_folder_path: "/home/yang/all_dataset"
ob_path: "/home/yang/dataset_subset"
image_size: 224
weight_decay: 0.2
checkpoint_file: "/home/yang/BLIP/clip_models/clip_config/ckpt-9/pytorch_model.bin"